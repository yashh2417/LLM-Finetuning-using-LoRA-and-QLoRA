{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6hJmLRVgzdwR7FjB+Oj6t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52d4b37e83224fc1a07eb5319477f05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4266639c3ae64d84a520d2571abbc55e",
              "IPY_MODEL_1671744e12e940f5932a309d1e4d233a",
              "IPY_MODEL_0051044040524deabd6b5086128c3eb8"
            ],
            "layout": "IPY_MODEL_037e49565bae47bc985b0b47d899ac91"
          }
        },
        "4266639c3ae64d84a520d2571abbc55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20565240c80457e9cf4d15c1456ca12",
            "placeholder": "​",
            "style": "IPY_MODEL_e1e21d40343f4c549b16cfaec25341b2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1671744e12e940f5932a309d1e4d233a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5267ce4948a47b5b526ad9d99490784",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73f04b1a7ce244fcbc9627d6cdbd6b98",
            "value": 2
          }
        },
        "0051044040524deabd6b5086128c3eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29dc4db5d32649c5a17873c843562879",
            "placeholder": "​",
            "style": "IPY_MODEL_216b60226d834f9f8e84e61ccde11bc0",
            "value": " 2/2 [00:24&lt;00:00, 10.73s/it]"
          }
        },
        "037e49565bae47bc985b0b47d899ac91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20565240c80457e9cf4d15c1456ca12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e21d40343f4c549b16cfaec25341b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5267ce4948a47b5b526ad9d99490784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f04b1a7ce244fcbc9627d6cdbd6b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29dc4db5d32649c5a17873c843562879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216b60226d834f9f8e84e61ccde11bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c60c0f81f27439f9f91cefb8afbaa5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbf5834b52ab4291a426aa2e786200f6",
              "IPY_MODEL_3e78bba7f8ff48cdaf0622bf698f15bf",
              "IPY_MODEL_3505422cda274414b64577d6444c3805"
            ],
            "layout": "IPY_MODEL_4d5653c3540e4d66afebc8c564b6fc42"
          }
        },
        "bbf5834b52ab4291a426aa2e786200f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cfe50c145c84eabb82f7e7ced079c95",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac92b0008bb4fa9801d804c2b44468c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3e78bba7f8ff48cdaf0622bf698f15bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5456c06a1544743a913d94e577f4d4a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ac58baba09b4881a98cfd8f225b6577",
            "value": 2
          }
        },
        "3505422cda274414b64577d6444c3805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c19adb784864e378e5163896d55986e",
            "placeholder": "​",
            "style": "IPY_MODEL_6cf7c5095882479c8e08e103e1e1d0aa",
            "value": " 2/2 [00:29&lt;00:00, 12.21s/it]"
          }
        },
        "4d5653c3540e4d66afebc8c564b6fc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfe50c145c84eabb82f7e7ced079c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac92b0008bb4fa9801d804c2b44468c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5456c06a1544743a913d94e577f4d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac58baba09b4881a98cfd8f225b6577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c19adb784864e378e5163896d55986e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf7c5095882479c8e08e103e1e1d0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "954ac0f855db4672bc473826eaaeb352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725943f6f30f40ac811b1484c78c356e",
              "IPY_MODEL_b56dd93f76074a80a73b3e750194b1a6",
              "IPY_MODEL_8e625028f6bf4ea6bf8ab5272180e43c"
            ],
            "layout": "IPY_MODEL_95eaa0b753ef4612ad1dfd8fba46df27"
          }
        },
        "725943f6f30f40ac811b1484c78c356e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa8c2c667b5430195a56a1efd718e49",
            "placeholder": "​",
            "style": "IPY_MODEL_764e6babc5784e6e8a0a09f01036a964",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b56dd93f76074a80a73b3e750194b1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e5f8529ba6745e3b537012cc34467aa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68f2339ead404e0cb4ff9931469cb82c",
            "value": 2
          }
        },
        "8e625028f6bf4ea6bf8ab5272180e43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde95893d6c643cfbf067253aebb93c0",
            "placeholder": "​",
            "style": "IPY_MODEL_23c0795940fb4c6181bb3ac9a75203b7",
            "value": " 2/2 [00:31&lt;00:00, 13.26s/it]"
          }
        },
        "95eaa0b753ef4612ad1dfd8fba46df27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa8c2c667b5430195a56a1efd718e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764e6babc5784e6e8a0a09f01036a964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e5f8529ba6745e3b537012cc34467aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f2339ead404e0cb4ff9931469cb82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cde95893d6c643cfbf067253aebb93c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c0795940fb4c6181bb3ac9a75203b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "436efa38ccbc42b6b2b17e9317f8ea6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3de05d73663f4c08b988da9ea58e3835",
              "IPY_MODEL_7def5b93ad5047eba2dc8cb9ff79762b",
              "IPY_MODEL_31894effd5204c60b28c5bf92365b6fe"
            ],
            "layout": "IPY_MODEL_4fe9a3c5c815469ea34ad698dc164e34"
          }
        },
        "3de05d73663f4c08b988da9ea58e3835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51a953f438af4e87b79be4561603f4e4",
            "placeholder": "​",
            "style": "IPY_MODEL_b066505b5e6f4508a2e35fa052da8ae7",
            "value": "Downloading builder script: 100%"
          }
        },
        "7def5b93ad5047eba2dc8cb9ff79762b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c963a94e9cc4bcc9a25b6968c4b1e40",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_850043dd66ec469eb8be4766b498b847",
            "value": 6270
          }
        },
        "31894effd5204c60b28c5bf92365b6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe2c86811de40ff83a9b5f03db97d2b",
            "placeholder": "​",
            "style": "IPY_MODEL_3cc63c4db61841658a6a679fca9d1f8c",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 204kB/s]"
          }
        },
        "4fe9a3c5c815469ea34ad698dc164e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a953f438af4e87b79be4561603f4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b066505b5e6f4508a2e35fa052da8ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c963a94e9cc4bcc9a25b6968c4b1e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850043dd66ec469eb8be4766b498b847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffe2c86811de40ff83a9b5f03db97d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc63c4db61841658a6a679fca9d1f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashh2417/LLM-Finetuning-using-LoRA-and-QLoRA/blob/main/phi2_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M45i3d3Ww78j",
        "outputId": "c6344fc1-5f06-41fe-f032-f90443e86c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.4/366.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    GenerationConfig\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from huggingface_hub import interpreter_login\n",
        "\n",
        "interpreter_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSgLiGIWw9ti",
        "outputId": "7491270b-be23-406e-f616-f53713c6f768"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your token (input will not be visible): ··········\n",
            "Add token as git credential? (Y/n) y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# disable Weights and Biases\n",
        "os.environ['WANDB_DISABLED']=\"true\""
      ],
      "metadata": {
        "id": "ThhIcAmqxfUO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_dataset_name = \"neil-code/dialogsum-test\"\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ],
      "metadata": {
        "id": "zC5I3MmXx2KJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDJ_T88Zx4Ty",
        "outputId": "c1fcdebc-e2bc-431b-be59-8d9526396d12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1999\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 499\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 499\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX3G6VxY0Qr3",
        "outputId": "a6e782e1-4559-4172-f100-c8cf07d90cab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'train_0',\n",
              " 'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\",\n",
              " 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\",\n",
              " 'topic': 'get a check-up'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0][\"id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-HLlrz6x9vN",
        "outputId": "dca72827-72ee-4766-eae8-e467d8670a36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0][\"dialogue\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T8sxSYFyA3i",
        "outputId": "bc327e42-e31a-4290-9eae-ca2f5b0845ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "#Person2#: I found it would be a good idea to get a check-up.\n",
            "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "#Person2#: Ok.\n",
            "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "#Person2#: Yes.\n",
            "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "#Person2#: Ok, thanks doctor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0][\"summary\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLZWpDnbyUKm",
        "outputId": "9de2ecc7-402f-44b7-f2b4-17d9f52a8e45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0][\"topic\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeLmqXdFyX0K",
        "outputId": "4421fc6d-29a9-4a31-8305-989fa1922f1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get a check-up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bits = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "    bnb_4bit_compute_dtype = torch.float16\n",
        ")"
      ],
      "metadata": {
        "id": "JCtV99K1yaDE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='microsoft/phi-2'\n",
        "device_map = {\"\": 0}\n",
        "original_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                                      device_map=device_map,\n",
        "                                                      quantization_config=bnb_config,\n",
        "                                                      trust_remote_code=True,\n",
        "                                                      use_auth_token=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "52d4b37e83224fc1a07eb5319477f05d",
            "4266639c3ae64d84a520d2571abbc55e",
            "1671744e12e940f5932a309d1e4d233a",
            "0051044040524deabd6b5086128c3eb8",
            "037e49565bae47bc985b0b47d899ac91",
            "d20565240c80457e9cf4d15c1456ca12",
            "e1e21d40343f4c549b16cfaec25341b2",
            "e5267ce4948a47b5b526ad9d99490784",
            "73f04b1a7ce244fcbc9627d6cdbd6b98",
            "29dc4db5d32649c5a17873c843562879",
            "216b60226d834f9f8e84e61ccde11bc0"
          ]
        },
        "id": "SqUAXylTyzKm",
        "outputId": "47116931-b0b2-4c89-fc2e-5b0542918d9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52d4b37e83224fc1a07eb5319477f05d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "rt-Bx55oy6tB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(model, prompt: str, max_new_tokens: int = 100):\n",
        "    \"\"\"Generate text with Hugging Face models, returning a list of strings.\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    output_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,          # deterministic because you set the seed\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    return tokenizer.batch_decode(output_ids, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "ja_XgykF3R_f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import set_seed\n",
        "seed = 42\n",
        "set_seed(seed)\n",
        "\n",
        "index = 10\n",
        "\n",
        "prompt = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "formatted_prompt = f\"Instruct: Summarize the following conversation.\\n{prompt}\\nOutput:\\n\"\n",
        "res = gen(original_model,formatted_prompt,100,)\n",
        "\n",
        "# print(res[0])\n",
        "output = res[0].split('Output:\\n')[1]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{formatted_prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UYsdPjV034n",
        "outputId": "c2020165-71f4-4cb0-a940-39515b6234dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "Instruct: Summarize the following conversation.\n",
            "#Person1#: Happy Birthday, this is for you, Brian.\n",
            "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
            "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
            "#Person2#: Ok.\n",
            "#Person1#: This is really wonderful party.\n",
            "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
            "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
            "#Person2#: You look great, you are absolutely glowing.\n",
            "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
            "Output:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "Person1 and Person2 are at a party, and Person1 asks if they can have a dance. Person2 agrees and compliments Person1 on their appearance. Person1 thanks them and expresses their happiness with the party. Person2 agrees that it's a great party and suggests having a drink to celebrate.\n",
            "\n",
            "CPU times: user 4.96 s, sys: 145 ms, total: 5.11 s\n",
            "Wall time: 5.92 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_formats(sample):\n",
        "    \"\"\"\n",
        "    Format various fields of the sample ('instruction','output')\n",
        "    Then concatenate them using two newline characters\n",
        "    :param sample: Sample dictionnary\n",
        "    \"\"\"\n",
        "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    INSTRUCTION_KEY = \"### Instruct: Summarize the below conversation.\"\n",
        "    RESPONSE_KEY = \"### Output:\"\n",
        "    END_KEY = \"### End\"\n",
        "\n",
        "    blurb = f\"\\n{INTRO_BLURB}\"\n",
        "    instruction = f\"{INSTRUCTION_KEY}\"\n",
        "    input_context = f\"{sample['dialogue']}\" if sample[\"dialogue\"] else None\n",
        "    response = f\"{RESPONSE_KEY}\\n{sample['summary']}\"\n",
        "    end = f\"{END_KEY}\"\n",
        "\n",
        "    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n",
        "\n",
        "    formatted_prompt = \"\\n\\n\".join(parts)\n",
        "    sample[\"text\"] = formatted_prompt\n",
        "\n",
        "    return sample"
      ],
      "metadata": {
        "id": "HrGTvKhv089O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = create_prompt_formats(dataset['train'][10])[\"text\"]"
      ],
      "metadata": {
        "id": "s_-VudRG0Im0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWD43v0a08Bb",
        "outputId": "edea52de-70ce-4fd4-a4f2-38b9633e37b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruct: Summarize the below conversation.\n",
            "\n",
            "#Person1#: Could you do me a favor?\n",
            "#Person2#: Sure. What is it?\n",
            "#Person1#: Could you run over to the store? We need a few things.\n",
            "#Person2#: All right. What do you want me to get?\n",
            "#Person1#: Well, could you pick up some sugar?\n",
            "#Person2#: Okay. How much?\n",
            "#Person1#: A small bag. I guess we also need a few oranges.\n",
            "#Person2#: How many?\n",
            "#Person1#: Oh, let's see. . . About six.\n",
            "#Person2#: Anything else?\n",
            "#Person1#: Yes. We're out of milk.\n",
            "#Person2#: Okay. How much do you want me to get? A gallon?\n",
            "#Person1#: No. I think a half gallon will be enough.\n",
            "#Person2#: Is that all?\n",
            "#Person1#: I think so. Have you got all that?\n",
            "#Person2#: Yes. That's small bag of sugar, four oranges, and a half gallon of milk.\n",
            "#Person1#: Do you have enough money?\n",
            "#Person2#: I think so.\n",
            "#Person1#: Thanks very much. I appreciate it.\n",
            "\n",
            "### Output:\n",
            "#Person1# asks #Person2# to do a favor. #Person2# agrees and helps buy a small bag of sugar, six oranges, and a half-gallon of milk.\n",
            "\n",
            "### End\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPGQXCL114cM",
        "outputId": "030741cb-0051-497e-d3f6-bddb5ebf477f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PhiConfig {\n",
              "  \"architectures\": [\n",
              "    \"PhiForCausalLM\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 50256,\n",
              "  \"embd_pdrop\": 0.0,\n",
              "  \"eos_token_id\": 50256,\n",
              "  \"hidden_act\": \"gelu_new\",\n",
              "  \"hidden_size\": 2560,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 10240,\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 2048,\n",
              "  \"model_type\": \"phi\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 32,\n",
              "  \"num_key_value_heads\": 32,\n",
              "  \"partial_rotary_factor\": 0.4,\n",
              "  \"qk_layernorm\": false,\n",
              "  \"quantization_config\": {\n",
              "    \"_load_in_4bit\": false,\n",
              "    \"_load_in_8bit\": false,\n",
              "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
              "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "    \"bnb_4bit_quant_type\": \"nf4\",\n",
              "    \"bnb_4bit_use_double_quant\": true,\n",
              "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "    \"llm_int8_has_fp16_weight\": false,\n",
              "    \"llm_int8_skip_modules\": null,\n",
              "    \"llm_int8_threshold\": 6.0,\n",
              "    \"load_in_4bit\": false,\n",
              "    \"load_in_8bit\": false,\n",
              "    \"quant_method\": \"bitsandbytes\"\n",
              "  },\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.52.4\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 51200\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
        "def get_max_length(model):\n",
        "    conf = model.config\n",
        "    max_length = None\n",
        "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
        "        max_length = getattr(model.config, length_setting, None)\n",
        "        if max_length:\n",
        "            print(f\"Found max lenth: {max_length}\")\n",
        "            break\n",
        "    if not max_length:\n",
        "        max_length = 1024\n",
        "        print(f\"Using default max length: {max_length}\")\n",
        "    return max_length\n",
        "\n",
        "\n",
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizing a batch\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
        "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int,seed, dataset):\n",
        "    \"\"\"Format & tokenize it so it is ready for training\n",
        "    :param tokenizer (AutoTokenizer): Model Tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prompt to each sample\n",
        "    print(\"Preprocessing dataset...\")\n",
        "    dataset = dataset.map(create_prompt_formats)#, batched=True)\n",
        "\n",
        "    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n",
        "    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
        "    dataset = dataset.map(\n",
        "        _preprocessing_function,\n",
        "        batched=True,\n",
        "        remove_columns=['id', 'topic', 'dialogue', 'summary'],\n",
        "    )\n",
        "\n",
        "    # Filter out samples that have input_ids exceeding max_length\n",
        "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "\n",
        "    # Shuffle dataset\n",
        "    dataset = dataset.shuffle(seed=seed)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "sW_Zg8h83aDf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pre-process dataset\n",
        "max_length = get_max_length(original_model)\n",
        "print(max_length)\n",
        "\n",
        "train_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['train'])\n",
        "eval_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['validation'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V-uV0TG3r1g",
        "outputId": "eb9aeaae-fd83-4e31-e4af-0cc160cb78b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found max lenth: 2048\n",
            "2048\n",
            "Preprocessing dataset...\n",
            "Preprocessing dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM9PrQXu3vDv",
        "outputId": "a389d8ee-df85-4c80-bb47-d0d453357006"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 1999\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfjU7Tp730_S",
        "outputId": "324a765c-3d3a-449f-d62d-a8698dd05c50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 499\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B45H61lR35ZY",
        "outputId": "b932b848-464f-44ce-c0f6-5beaed245ccb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruct: Summarize the below conversation.\n",
            "\n",
            "#Person1#: How are your French lessons going?\n",
            "#Person2#: Well, I'm no longer taking French lessons.\n",
            "#Person1#: Are you kidding? You told me you made up your mind to study French well this summer. Didn't you sign up for the four-week course?\n",
            "#Person2#: I did. But the teacher told me not to come back any more after only one week and he returned my money for the remaining three weeks.\n",
            "#Person1#: How come? I've never heard of a case like that before. Did you have a quarrel with your teacher?\n",
            "#Person2#: Of course not. At first everything went well and he was satisfied with me. But he got angry after I broke the class rules several times.\n",
            "#Person1#: It was your fault, I think. You'd gone too far.\n",
            "#Person2#: Perhaps. But I don't understand why he told me to stop coming. He was very kind, you know.\n",
            "#Person1#: Just forget it.\n",
            "\n",
            "### Output:\n",
            "#Person2# is no longer taking French lessons because #Person2# has been kicked out for broking the class rules several times. #Person1# comforts #Person2#.\n",
            "\n",
            "### End\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 - Using the prepare_model_for_kbit_training method from PEFT\n",
        "# Preparing the Model for QLoRA\n",
        "\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "original_model = prepare_model_for_kbit_training(original_model)"
      ],
      "metadata": {
        "id": "AUvF0X0e4C2y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=32, #Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        'q_proj',\n",
        "        'k_proj',\n",
        "        'v_proj',\n",
        "        'dense'\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\n",
        "original_model.gradient_checkpointing_enable()\n",
        "\n",
        "peft_model = get_peft_model(original_model, config)"
      ],
      "metadata": {
        "id": "1RYuzA3E4kH9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAXOg5sx4upo",
        "outputId": "114d8042-7998-4433-b100-4cc822787a97"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): PhiForCausalLM(\n",
              "      (model): PhiModel(\n",
              "        (embed_tokens): Embedding(51200, 2560)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x PhiDecoderLayer(\n",
              "            (self_attn): PhiAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (dense): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): PhiMLP(\n",
              "              (activation_fn): NewGELUActivation()\n",
              "              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (rotary_emb): PhiRotaryEmbedding()\n",
              "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_params = 0\n",
        "    for param in model.parameters():\n",
        "        all_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "    print(f\"Trainable params: {trainable_params}\")\n",
        "    print(f\"All params: {all_params}\")\n",
        "    print(f\"Trainable%: {100 * trainable_params / all_params:.2f}%\")\n"
      ],
      "metadata": {
        "id": "2xZMXVqX5PC7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg8XZel04xIn",
        "outputId": "83e787a5-114c-4c9a-b925-2d3319d9abba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 20971520\n",
            "All params: 1542364160\n",
            "Trainable%: 1.36%\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
        "import transformers\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    warmup_steps=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    max_steps=100,\n",
        "    learning_rate=2e-4,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    logging_steps=25,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=25,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    do_eval=True,\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir = 'True',\n",
        "    group_by_length=True,\n",
        ")\n",
        "\n",
        "peft_model.config.use_cache = False\n",
        "\n",
        "peft_trainer = transformers.Trainer(\n",
        "    model=peft_model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=peft_training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHH5Fvj_47BV",
        "outputId": "91c4ac1e-9dde-47f9-9d47-a3c07f9a0101"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "p0c0e-uh5V7_",
        "outputId": "229bae36-60a2-4884-8a6d-60ba2741c817"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 11:49, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.672500</td>\n",
              "      <td>1.369777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.197600</td>\n",
              "      <td>1.333519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.445800</td>\n",
              "      <td>1.323340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.217000</td>\n",
              "      <td>1.314662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.3832330322265625, metrics={'train_runtime': 716.7003, 'train_samples_per_second': 0.558, 'train_steps_per_second': 0.14, 'total_flos': 1846465383444480.0, 'train_loss': 1.3832330322265625, 'epoch': 0.2001000500250125})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "base_model_id = \"microsoft/phi-2\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(base_model_id,\n",
        "                                                      device_map='auto',\n",
        "                                                      quantization_config=bnb_config,\n",
        "                                                      trust_remote_code=True,\n",
        "                                                      use_auth_token=True)"
      ],
      "metadata": {
        "id": "XF02xSPx6O76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "4c60c0f81f27439f9f91cefb8afbaa5e",
            "bbf5834b52ab4291a426aa2e786200f6",
            "3e78bba7f8ff48cdaf0622bf698f15bf",
            "3505422cda274414b64577d6444c3805",
            "4d5653c3540e4d66afebc8c564b6fc42",
            "9cfe50c145c84eabb82f7e7ced079c95",
            "7ac92b0008bb4fa9801d804c2b44468c",
            "e5456c06a1544743a913d94e577f4d4a",
            "9ac58baba09b4881a98cfd8f225b6577",
            "4c19adb784864e378e5163896d55986e",
            "6cf7c5095882479c8e08e103e1e1d0aa"
          ]
        },
        "outputId": "530e173c-4310-4a3b-890a-eece4fbb8ebc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c60c0f81f27439f9f91cefb8afbaa5e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
        "eval_tokenizer.pad_token = eval_tokenizer.eos_token"
      ],
      "metadata": {
        "id": "fpBnf5GB-3Bm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"peft-dialogue-summary-training-1750063934/checkpoint-100\",torch_dtype=torch.float16,is_trainable=False)"
      ],
      "metadata": {
        "id": "9CanNsuY-6jp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import set_seed\n",
        "set_seed(seed)\n",
        "\n",
        "index = 10\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"Instruct: Summarize the following conversation.\\n{dialogue}\\nOutput:\\n\"\n",
        "\n",
        "peft_model_res = gen(ft_model,prompt,100,)\n",
        "peft_model_output = peft_model_res[0].split('Output:\\n')[1]\n",
        "#print(peft_model_output)\n",
        "prefix, success, result = peft_model_output.partition('###')\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'PEFT MODEL:\\n{prefix}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABGm8ZY5BhhW",
        "outputId": "f427898a-6bc7-481e-eea9-77a320cd1661"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "Instruct: Summarize the following conversation.\n",
            "#Person1#: Happy Birthday, this is for you, Brian.\n",
            "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
            "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
            "#Person2#: Ok.\n",
            "#Person1#: This is really wonderful party.\n",
            "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
            "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
            "#Person2#: You look great, you are absolutely glowing.\n",
            "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
            "Output:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "PEFT MODEL:\n",
            "Brian's birthday party is a success. Brian and #Person1# have a dance and #Person1# compliments Brian's appearance. They both have a drink together to celebrate.\n",
            "\n",
            "#End of output#.\n",
            "\n",
            "CPU times: user 5.76 s, sys: 4.8 ms, total: 5.76 s\n",
            "Wall time: 6.96 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_model = AutoModelForCausalLM.from_pretrained(base_model_id,\n",
        "                                                      device_map='auto',\n",
        "                                                      quantization_config=bnb_config,\n",
        "                                                      trust_remote_code=True,\n",
        "                                                      use_auth_token=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "954ac0f855db4672bc473826eaaeb352",
            "725943f6f30f40ac811b1484c78c356e",
            "b56dd93f76074a80a73b3e750194b1a6",
            "8e625028f6bf4ea6bf8ab5272180e43c",
            "95eaa0b753ef4612ad1dfd8fba46df27",
            "3fa8c2c667b5430195a56a1efd718e49",
            "764e6babc5784e6e8a0a09f01036a964",
            "9e5f8529ba6745e3b537012cc34467aa",
            "68f2339ead404e0cb4ff9931469cb82c",
            "cde95893d6c643cfbf067253aebb93c0",
            "23c0795940fb4c6181bb3ac9a75203b7"
          ]
        },
        "id": "rZsCDJyWCCOl",
        "outputId": "0bfb564b-0716-44b6-aadd-99c1ba50098f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "954ac0f855db4672bc473826eaaeb352"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "    human_baseline_text_output = human_baseline_summaries[idx]\n",
        "    prompt = f\"Instruct: Summarize the following conversation.\\n{dialogue}\\nOutput:\\n\"\n",
        "\n",
        "    original_model_res = gen(original_model,prompt,100,)\n",
        "    original_model_text_output = original_model_res[0].split('Output:\\n')[1]\n",
        "\n",
        "    peft_model_res = gen(ft_model,prompt,100,)\n",
        "    peft_model_output = peft_model_res[0].split('Output:\\n')[1]\n",
        "    print(peft_model_output)\n",
        "    peft_model_text_output, success, result = peft_model_output.partition('###')\n",
        "\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "    peft_model_summaries.append(peft_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, peft_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'peft_model_summaries'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0G_e4vJCbNl",
        "outputId": "773d96c6-ea16-42f2-8859-820fa256d923"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ms. Dawson takes a dictation for #Person1#, who wants to restrict all office communications to email correspondence and official memos. Ms. Dawson will get the memo typed up and distributed to all employees before 4 pm.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ms. Dawson takes a dictation for #Person1#, who wants to restrict all office communications to email correspondence and official memos. Ms. Dawson will get the memo typed up and distributed to all employees before 4 pm.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ms. Dawson takes a dictation for #Person1#, who wants to restrict all office communications to email correspondence and official memos. Ms. Dawson will get the memo typed up and distributed to all employees before 4 pm.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person2# decides to quit driving to work and start taking public transport system and biking to work.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person2# decides to quit driving to work and start taking public transport system and biking to work.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person2# decides to quit driving to work and start taking public transport system and biking to work.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kate tells #Person2# that Masha and Hero are getting divorced. They are having a separation for 2 months and filed for divorce. Masha and Hero are well matched and no quarrelling about who get the house and stock. The divorce will be final in the New Year.\n",
            "\n",
            "#Person1#: Kate, you never believe what's happened.\n",
            "#Person2#: What do you mean?\n",
            "#Person1#: Well, I don't really know, but\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kate tells #Person2# that Masha and Hero are getting divorced. They are having a separation for 2 months and filed for divorce. Masha and Hero are well matched and no quarrelling about who get the house and stock. The divorce will be final in the New Year.\n",
            "\n",
            "#Person1#: Kate, you never believe what's happened.\n",
            "#Person2#: What do you mean?\n",
            "#Person1#: Well, I don't really know, but\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kate tells #Person2# that Masha and Hero are getting divorced. They are having a separation for 2 months and filed for divorce. Masha and Hero are well matched and no quarrelling about who get the house and stock. The divorce will be final in the New Year.\n",
            "\n",
            "#Person1#: Kate, you never believe what's happened.\n",
            "#Person2#: What do you mean?\n",
            "#Person1#: Well, I don't really know, but\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brian's birthday party is a success. Brian and #Person1# have a dance and #Person1# compliments Brian's appearance. They both have a drink together to celebrate.\n",
            "\n",
            "#End of output#.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
              "1  In order to prevent employees from wasting tim...   \n",
              "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
              "3  #Person2# arrives late because of traffic jam....   \n",
              "4  #Person2# decides to follow #Person1#'s sugges...   \n",
              "5  #Person2# complains to #Person1# about the tra...   \n",
              "6  #Person1# tells Kate that Masha and Hero get d...   \n",
              "7  #Person1# tells Kate that Masha and Hero are g...   \n",
              "8  #Person1# and Kate talk about the divorce betw...   \n",
              "9  #Person1# and Brian are at the birthday party ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  Person 1: Ms. Dawson, I need you to take a dic...   \n",
              "1  Person 1: Ms. Dawson, I need you to take a dic...   \n",
              "2  Person 1: Ms. Dawson, I need you to take a dic...   \n",
              "3  Person1 and Person2 are discussing the traffic...   \n",
              "4  Person1 and Person2 are discussing the traffic...   \n",
              "5  Person1 and Person2 are discussing the traffic...   \n",
              "6  Kate informed that Masha and Hero are getting ...   \n",
              "7  Kate informed that Masha and Hero are getting ...   \n",
              "8  Kate informed that Masha and Hero are getting ...   \n",
              "9  Person1 and Person2 are at a party, and Person...   \n",
              "\n",
              "                                peft_model_summaries  \n",
              "0  Ms. Dawson takes a dictation for #Person1#, wh...  \n",
              "1  Ms. Dawson takes a dictation for #Person1#, wh...  \n",
              "2  Ms. Dawson takes a dictation for #Person1#, wh...  \n",
              "3  #Person2# decides to quit driving to work and ...  \n",
              "4  #Person2# decides to quit driving to work and ...  \n",
              "5  #Person2# decides to quit driving to work and ...  \n",
              "6  Kate tells #Person2# that Masha and Hero are g...  \n",
              "7  Kate tells #Person2# that Masha and Hero are g...  \n",
              "8  Kate tells #Person2# that Masha and Hero are g...  \n",
              "9  Brian's birthday party is a success. Brian and...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe1a6f76-7461-4ccb-871b-7ec20e7e57ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>peft_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
              "      <td>Person 1: Ms. Dawson, I need you to take a dic...</td>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1#, wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In order to prevent employees from wasting tim...</td>\n",
              "      <td>Person 1: Ms. Dawson, I need you to take a dic...</td>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1#, wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
              "      <td>Person 1: Ms. Dawson, I need you to take a dic...</td>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1#, wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Person2# arrives late because of traffic jam....</td>\n",
              "      <td>Person1 and Person2 are discussing the traffic...</td>\n",
              "      <td>#Person2# decides to quit driving to work and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
              "      <td>Person1 and Person2 are discussing the traffic...</td>\n",
              "      <td>#Person2# decides to quit driving to work and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
              "      <td>Person1 and Person2 are discussing the traffic...</td>\n",
              "      <td>#Person2# decides to quit driving to work and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
              "      <td>Kate informed that Masha and Hero are getting ...</td>\n",
              "      <td>Kate tells #Person2# that Masha and Hero are g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
              "      <td>Kate informed that Masha and Hero are getting ...</td>\n",
              "      <td>Kate tells #Person2# that Masha and Hero are g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
              "      <td>Kate informed that Masha and Hero are getting ...</td>\n",
              "      <td>Kate tells #Person2# that Masha and Hero are g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
              "      <td>Person1 and Person2 are at a party, and Person...</td>\n",
              "      <td>Brian's birthday party is a success. Brian and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe1a6f76-7461-4ccb-871b-7ec20e7e57ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe1a6f76-7461-4ccb-871b-7ec20e7e57ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe1a6f76-7461-4ccb-871b-7ec20e7e57ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d828de6-c59c-4ab9-8209-3142ea70728e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d828de6-c59c-4ab9-8209-3142ea70728e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d828de6-c59c-4ab9-8209-3142ea70728e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbacf2f5-0567-491b-8a19-1ff64551b71f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbacf2f5-0567-491b-8a19-1ff64551b71f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"#Person1# and Kate talk about the divorce between Masha and Hero. Kate feels surprised because she thought they are well matched\",\n          \"In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\",\n          \"#Person2# complains to #Person1# about the traffic jam, #Person1# suggests quitting driving and taking public transportation instead.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Person1 and Person2 are discussing the traffic congestion near the Carrefour intersection. Person2 explains that they got stuck in traffic again and suggests that Person1 consider taking public transport to work. Person1 agrees that it would be better for the environment and suggests biking as an alternative. Person2 acknowledges the benefits of biking but expresses concern about missing the freedom of having a car. Person1 suggests that biking would provide the same freedom and offers to help Person2 get started. Person2 ultimately decides to\",\n          \"Person1 and Person2 are at a party, and Person1 asks if they can have a dance. Person2 agrees and compliments Person1 on their appearance. Person1 thanks them and expresses their happiness with the party. Person2 agrees that it's a great party and suggests having a drink to celebrate.\\n\",\n          \"Person 1: Ms. Dawson, I need you to take a dictation for me.\\nPerson 2: Yes, sir...\\nPerson 1: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\\nPerson 2: Yes, sir. Go ahead.\\nPerson 1: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peft_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"#Person2# decides to quit driving to work and start taking public transport system and biking to work.\\n\",\n          \"Brian's birthday party is a success. Brian and #Person1# have a dance and #Person1# compliments Brian's appearance. They both have a drink together to celebrate.\\n\\n#End of output#.\\n\",\n          \"Ms. Dawson takes a dictation for #Person1#, who wants to restrict all office communications to email correspondence and official memos. Ms. Dawson will get the memo typed up and distributed to all employees before 4 pm.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)\n",
        "\n",
        "print(\"Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "436efa38ccbc42b6b2b17e9317f8ea6d",
            "3de05d73663f4c08b988da9ea58e3835",
            "7def5b93ad5047eba2dc8cb9ff79762b",
            "31894effd5204c60b28c5bf92365b6fe",
            "4fe9a3c5c815469ea34ad698dc164e34",
            "51a953f438af4e87b79be4561603f4e4",
            "b066505b5e6f4508a2e35fa052da8ae7",
            "2c963a94e9cc4bcc9a25b6968c4b1e40",
            "850043dd66ec469eb8be4766b498b847",
            "ffe2c86811de40ff83a9b5f03db97d2b",
            "3cc63c4db61841658a6a679fca9d1f8c"
          ]
        },
        "id": "ivTwwS1PCeRe",
        "outputId": "803bc642-2d54-4b90-a894-f8cff991f7cd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "436efa38ccbc42b6b2b17e9317f8ea6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': np.float64(0.27956490338595374), 'rouge2': np.float64(0.10248384724361698), 'rougeL': np.float64(0.19801384523837195), 'rougeLsum': np.float64(0.2094128777920073)}\n",
            "PEFT MODEL:\n",
            "{'rouge1': np.float64(0.3782188219428972), 'rouge2': np.float64(0.13308129951224093), 'rougeL': np.float64(0.29427301533872174), 'rougeLsum': np.float64(0.3104481183793807)}\n",
            "Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\n",
            "rouge1: 9.87%\n",
            "rouge2: 3.06%\n",
            "rougeL: 9.63%\n",
            "rougeLsum: 10.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = \"\"\"One rainy evening, Maya was walking home from work when she realized her house key was missing. She searched every pocket, emptied her bag, and retraced her steps — nothing.\n",
        "\n",
        "She stood at her doorstep, wet and worried, when her neighbor, Mr. Rao, noticed her from across the hall.\n",
        "\n",
        "\"Locked out?\" he asked kindly.\n",
        "\n",
        "She nodded. \"I think I dropped my key somewhere.\"\n",
        "\n",
        "Mr. Rao handed her a hot cup of tea. \"Let’s think calmly.\"\n",
        "\n",
        "Just then, Maya remembered: she had used the side pocket of her bag for the first time that day. She opened it — and there it was, cold and metallic, waiting patiently.\n",
        "\n",
        "She laughed in relief.\n",
        "\n",
        "\"Sometimes,\" Mr. Rao smiled, \"we just need a little tea to find what we’re missing.\"\"\"\n",
        "\n",
        "prompt = f\"Instruct: Summarize the following conversation.\\n{dialogue}\\nOutput:\\n\"\n",
        "\n",
        "peft_model_res = gen(ft_model,prompt,100,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFd_uB0aDJ80",
        "outputId": "ecf603c7-793e-4dc2-ecbf-487664517f37"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(peft_model_res[0].split('Output:\\n')[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQxOblBuEKjg",
        "outputId": "cae4fd91-1ba5-4087-b43b-b092f96b910a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maya lost her house key and was worried. Mr. Rao offered her a cup of tea and helped her find the key in the side pocket of her bag.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cjTlYXzUESD1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}